{
 "metadata": {
  "name": "tutorial-3-sentiment-analysis.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tutorial 3. Sentiment analysis on the Twitter textual data\n",
      "==="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.1 Introduction and setup\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this tutorial is to guide you through the construction of a very basic sentiment analysis tool.\n",
      "We aim at detecting the polarity of a given text: is the attitude of the writer **positive** or **negative**.\n",
      "Texts such as `'This view is amazing'` are considered positive, whereas text as `'This view is horrible'` will be considered negative. Such a tool can be useful, for example, to detect if products reviews are positive or negative.\n",
      "The tool that we will construct starts from a very simple hypothesis: *it a text contains mainly positive words, then the general sentiment is positive; if the text contains mainly negative words, then the sentiment is negative*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Step 1:** For this purpose, we will use a sentiment lexicon: a list of words together with their polarity (*i.e.*, positive or negative).\n",
      "We use the lexicon described in \n",
      "`Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, Washington, USA.`,\n",
      "and available for [download here](http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html).  \n",
      "  \n",
      "In order to speed up this tutorial, we have downloaded the lexicon and pre-treated it (*i.e.*, we removed the header).\n",
      "Save into your current folder the two lexicon files: [sentiment-lexicon-positive-words.txt](http://mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/sentiment-lexicon-positive-words.txt) and [sentiment-lexicon-negative-words.txt](http://mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/sentiment-lexicon-negative-words.txt).\n",
      "Please note that some words in the lexicon are intentionally misspelled in order to accommodate common errors found in social media."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Step 2:** We will require to verify if the words in target text belong to the negative or to the positive lexicon.\n",
      "For this, we use the Python's powerful [NLTK (Natural Language Toolkit) module](http://www.nltk.org/).\n",
      "NLTK contains a comprehensive number of tools needed for natural text processing: tokenizers, stemmers, lemmatizers *etc.*\n",
      "In the following, we will use a tokenizer (a tool which splits natural language text into tokens - words) and a lemmatizer (a tool to reduce a word to its lemma - singular, masculine form for nouns, infinitive for verbs *etc.*)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you followed [the installation instructions](http://nbviewer.ipython.org/url/mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/install-instructions.ipynb), the *nltk* module should already be installed, alongside with the additional required data that the tokenizer requires.\n",
      "If you are outside of ANU's network, you can download this additional data by executing the code below.\n",
      "A window will open letting you chose what to download.\n",
      "Select the \"Corpora\" tab, scroll down and select \"wordnet\".\n",
      "This will require a download of 10.3MB.  \n",
      "\n",
      "**OBS:** inside the ANU's network, you must install the additional data as shown in the [the installation instructions](http://nbviewer.ipython.org/url/mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/install-instructions.ipynb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.googlecode.com/svn/trunk/nltk_data/index.xml\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now set up to start building our sentiment analysis tool."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.2 Constructing a basic sentiment analysis tool\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start by initializing a set of positive and negative examples to work with. The examples were taken from [this sentiment analysis tutorial](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tweets = [ 'I love this car',\n",
      "               'This view is amazing',\n",
      "\t           'I feel great this morning',\n",
      "\t           'I am so excited about the concert',\n",
      "\t           'He is my best friend']\n",
      "\n",
      "neg_tweets = ['I do not like this car',\n",
      "              'This view is horrible',\n",
      "              'I feel tired this morning',\n",
      "              'I am not looking forward to the concert',\n",
      "              'He is my enemy']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we import the positive and the negative lexicons.\n",
      "The format of the lexicon files is one word per line.\n",
      "As we will lemmatize the words in the target text, we apply the same treatment to the words in the lexicon."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "\n",
      "# define the lemmatizer\n",
      "lmtzr = WordNetLemmatizer()\n",
      "\n",
      "# read the positive and negative lexicon in lists of words\n",
      "positive_words = [lmtzr.lemmatize(line.strip()) for line in open('sentiment-lexicon-positive-words.txt')]\n",
      "negative_words = [lmtzr.lemmatize(line.strip()) for line in open('sentiment-lexicon-negative-words.txt')]\n",
      "\n",
      "print \"We have {:d} positive words and {:d} negative words.\".format(len(positive_words), len(negative_words))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "We have 2006 positive words and 4783 negative words.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to preprocess the target texts:\n",
      "* the text is split into tokens (words) by using **nltk**;\n",
      "* each token is transformed to lowercase;\n",
      "* tokens are lemmatized;\n",
      "* tokens with fewer than 3 characters are filtered out, since there are likely to be errors or non-sentiment related words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for words in pos_tweets + neg_tweets:\n",
      "    # tokenize and lemmatize the current tweet\n",
      "    tokens = nltk.word_tokenize(words)\n",
      "    tweet = [lmtzr.lemmatize(x.lower()) for x in tokens if len(x) >= 3]\n",
      "    \n",
      "    # print the tweet\n",
      "    print tweet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['love', 'this', 'car']\n",
        "['this', 'view', 'amazing']\n",
        "['feel', 'great', 'this', 'morning']\n",
        "['excited', 'about', 'the', 'concert']\n",
        "['best', 'friend']\n",
        "['not', 'like', 'this', 'car']\n",
        "['this', 'view', 'horrible']\n",
        "['feel', 'tired', 'this', 'morning']\n",
        "['not', 'looking', 'forward', 'the', 'concert']\n",
        "['enemy']\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the end, for each text we compute a score:\n",
      "* if a given word is in the positive list, we add one to the score;\n",
      "* if the word is in the negative list, we subtract one from the score.\n",
      "\n",
      "In the end, if the score is greater than zero, the text is considered as positive. \n",
      "If it is less than zero, it is considered negative. \n",
      "If it is zero, the text is considered neutral."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following code finds and outputs the positive and negative words in the texts. \n",
      "It computes the score and prints it out for each text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sentiment_score(text):\n",
      "    # tokenize and lemmatize the current tweet\n",
      "    tokens = nltk.word_tokenize(text)\n",
      "    tweet = [lmtzr.lemmatize(x.lower()) for x in tokens if len(x) >= 3]\n",
      "\n",
      "    # calculate the sentiment score\n",
      "    score = 0\n",
      "    for word in tweet:\n",
      "        if word in positive_words:\n",
      "            score = score + 1\n",
      "            print \"+1\", word\n",
      "        if word in negative_words:\n",
      "            score = score - 1\n",
      "            print \"-1\", word\n",
      "    \n",
      "    return score\n",
      "\n",
      "# apply it on our example tweets\n",
      "for words in pos_tweets + neg_tweets:\n",
      "    print \"Tweet: '{:s}', score: {:d}\".format(words, get_sentiment_score(words))\n",
      "    print \"------------------------------------\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+1 love\n",
        "Tweet: 'I love this car', score: 1\n",
        "------------------------------------\n",
        "+1 amazing\n",
        "Tweet: 'This view is amazing', score: 1\n",
        "------------------------------------\n",
        "+1 great\n",
        "Tweet: 'I feel great this morning', score: 1\n",
        "------------------------------------\n",
        "+1 excited\n",
        "Tweet: 'I am so excited about the concert', score: 1\n",
        "------------------------------------\n",
        "+1 best\n",
        "Tweet: 'He is my best friend', score: 1\n",
        "------------------------------------\n",
        "+1 like\n",
        "Tweet: 'I do not like this car', score: 1\n",
        "------------------------------------\n",
        "-1 horrible\n",
        "Tweet: 'This view is horrible', score: -1\n",
        "------------------------------------\n",
        "-1 tired\n",
        "Tweet: 'I feel tired this morning', score: -1\n",
        "------------------------------------\n",
        "Tweet: 'I am not looking forward to the concert', score: 0\n",
        "------------------------------------\n",
        "-1 enemy\n",
        "Tweet: 'He is my enemy', score: -1\n",
        "------------------------------------\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We observe that all the positive examples have been detected as positive, because they contain positive words.\n",
      "Only 3 out of 5 negative examples were detected as such.\n",
      "In the case of *'I do not like this car'*, the word **like** is in the positive list, but in the text it is prefixed by **not** which changes the polarity.\n",
      "**like** is positive, but **not like** is negative.\n",
      "*'I am not looking forward to the concert'* does not contain any positive or negative words, even if the expression **not looking forward** has a negative connotation.\n",
      "This shows the limitations of our naive approach.\n",
      "These special cases should be taken into account."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.3 Applying the analysis on real data: assignments for you\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**(1 point) Assignment question #3.1:** Use the `get_sentiment_score(text)`, the sentiment scoring function defined before, and calculate the sentiment polarity of the tweets in the Twitter JSON dataset used in [tutorial 2](http://nbviewer.ipython.org/url/mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/tutorial-2-construct-network-real-twitter-dump.ipynb). \n",
      "The dataset is [available to download here](http://mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/twitter-dump.json.bz2). \n",
      "Print the text of the 10 most positive and the 10 most negative tweets. \n",
      "We consider that a tweet $t_1$ is more positive than another tweet $t_2$ when score of the former is higher than the score of the latter ($score(t_1) > score(t_2)$). \n",
      "Similarly, a tweet $t_1$ is more negative than $t_2$ when $score(t_1) < score(t_2)$.  \n",
      "**HINT:** Load the tweets one by one as seen in tutorial 2 and extract the text, which is found in the field *text* of each tweet."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**(1 point) Assignment question #3.2:** Based on the scores calculated in **Assignment #3.1**, determine the 3 most positive users. A user $u_1$ is more positive than a user $u_2$ if the dataset contains more positive tweets emitted by $u_1$ than tweets emitted by $u_2$. Formally:\n",
      "$$ positivity(u_1) > positivity(u_2) \\iff \\left| \\left\\{ t \\, \\middle| \\, author(t) = u_1 \\wedge score(t) > 0 \\right\\} \\right| > \\left| \\left\\{ t \\, \\middle| \\, author(t) = u_2 \\wedge score(t) > 0 \\right\\} \\right|$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Bonus assignment (1 additional points will be given if you solve this assignment correctly, no penalty if you do not solve it. Note that the total grade of SMA assignments cannot exceed 8 points, therefore the bonus point can only be used to compensate for another question which you did not solve correctly):**  \n",
      "We have discussed earlier that our system is fragile to negations: it will score the expression *not beautiful* as positive because it only detects the word beautiful as positive. \n",
      "More generally, we consider that the token **not** changes the polarity of a given token: **not beautiful** becomes negative, while **not bad** becomes positive.  \n",
      "Modify the function `get_sentiment_score(text)` to detect the changes of polarity due to the token **not**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optional assignments\n",
      "---\n",
      "The purpose of the optional assignments here after is to guide you into a more in depth analysis of the social network.\n",
      "These assignments are optional and **they will not graded**.\n",
      "Whatsoever, if you have questions regarding them, you may discuss them with your tutor or post them on the forum."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Optional assignment question:** Based on the scores calculated in **Assignment #3.1**, plot the temporal evolution of the counts of positive and negative tweets. The date a tweet was emitted is found in the field *created_at*. Divide the temporal extent is of your dataset into 100 timeslices. The temporal extent of the dataset is from the creation date of the first tweet to the creation date of the last tweet. Count how many positive and how many negative tweets you have in each timeslice. Plot these counts on a graphic resembling this one:  \n",
      "![caption](files/desired-plot.png)  \n",
      "**HINT:** the graphic above is not based on real data. Your actual curves might **NOT** look like this one. Its purpose is just to show you the expected form of the graphic."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Optional assignment question: Polarized communities** We want to know if there are polarized communities in our social graph. Are there closely linked groups of users who have similar sentiment polarities? We calculate the sentiment polarity of a user as the numbre of positive tweets emitted, from which we substract the number of negative tweets. Formally:\n",
      "$$sentiment\\_polarity(u) = \\left| \\left\\{ t \\, \\middle| \\, author(t) = u \\wedge score(t) > 0 \\right\\} \\right| - \\left| \\left\\{ t \\, \\middle| \\, author(t) = u \\wedge score(t) < 0 \\right\\} \\right| \\enspace.$$  \n",
      "To visually detect the polarized communities, we want to plot the same graph as in [tutorial 1](http://nbviewer.ipython.org/url/mediamining.univ-lyon2.fr/~andrei/sna-lab-ipython/tutorial-1-construct-social-graph.ipynb) at *Step 3*, but with the colors of nodes representing their polarity: `blue` for a negative polarity and `red` for a positive polarity. \n",
      "Are nodes colored similarly clustered close together?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}