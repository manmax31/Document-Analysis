specified the attributes of the "ideal" book, they are translated into a LOOM query. If this query succeeds, the user's requirements are matched perfectly   a non-typical case. Should the number of books retrieved be less than four (including zero), the search attributes are relaxed step-by-step in order to produce more matches, up to the point where four books have been retrieved. (If more than four result, a random selection is made.) This occurs according to a pre-defined relaxation sequence: First look for "similar" topics covered by the book, then relax the requirements on code examples and exercises, then on the programming language; the least flexible attribute is the language of the book, for if the user has explicitly specified one language, they probably will not welcome a book in another.2 The number and weight of relaxed constraints define a ranking of the books, which leads to the establishment of communicative goals.
3.2 Determine communicative goals and attributes to be verbalized
The book database has some 15 different at-
tributes (author, title, publisher, year, pages,
topics covered, exercises, etc.), not all of which are to be included in a book's description. The list of attributes to include is not pre-stored, but arises from four different sources:
•	Identificational attributes: trivially, author
name and book title are always included.
•	Atypical attributes: book is very long or very short; very old or very recent; covers very many or very few topics, etc. (determined by comparing to "typicality threshold", which is computed over the whole range of entries)
•	Un-/desired attributes: those that match the user's target values very well, and those that are in conflict
•	Comparative attributes: similarities and differences between this book and the one described previously
Those attributes that relate to the user's tar-
get feature specification receive an evaluation
~ ~ principle, the relaxation sequence could also be
specified by the user, but for now it is hard-wired.
that reflects the degree of the mis/match com-
bined with the importance of the feature; val-
ues are arranged on a numerical scale from +3 to -3. Next, for each book a communicative goal is computed, which abstratcs over the candidate ranking and the factors used for evaluating the suitability. Depending on the closeness of the match and the distance to the competitors, for the first book presented the goal is one of describe-and-highly-recommend, describeand-recommend, and describe; for subsequent books, compare is added to the labels.
3.3 Map DB attributes to propositions Before we can construct a text plan that represents the propositional contents of the text, the individual DB attributes are mapped to a level of propositions; this often involves aggregation of attributes. Examples:
•	The author and title attributes can be combined into a "(WRITTEN-BY title author)" proposition.
•	Binary features like has-exercises and hascode-examples can be combined into a proposition "(CONTAINS book (and exercises code))".
•	A feature that is relevant to the user can be re-formulated by a computation. In our sample text in fig. 1, this applied to (YEAR 1990), which was in conflict with the user's wish for a recent book, and hence was mapped to the proposition "(OLD book 12yrs)" .
•	If the book is evaluated very positively, a distinct "(RECOMMEND book)" proposition can be added.
Notice that propositions are still "pre-verbal"; in the sentence planning stage, lexicalization will choose from a range of lexemes that can express the given content.
3.4 Build a rhetorical tree
As in many current generation systems, a text
plan amounts to a tree of propositions and
"rhetorical relations", as inspired by (Mann, Thompson 1987). Unlike many current systems, however, we distinguish between the rhetorical relations in the text plan and the more surface- oriented "conjunctive relations" (Martin 1992)
