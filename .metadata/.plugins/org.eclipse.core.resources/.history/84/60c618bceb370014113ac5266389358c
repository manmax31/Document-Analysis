package KMeans;

import java.io.File;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.HashMap;
import java.util.Set;
import java.util.stream.Collectors;

import util.FileFinder;

public class Files2BigDictionary 
{
	//static Map<String, Map> bigFileDictionary = new HashMap<String, Map>(); // {fileName1: {wordFreqMap}, ...}
	
	/*
	 * This function reads each file in a directory, calculates the frequency of each word in a file and creates a wordFreqMap of that file
	 * It then puts the fileName and its wordFreqMap to bigFileDictionary
	 * @param directory         : path to directory
	 * @param ignore_stop_words : true to ignore stop words
	 */
	public static Map<String, Map> filesToHashMap(String directory, boolean ignore_stop_words)
	{
		
		Map<String, Map> bigFileDictionary = new HashMap<String, Map>(); // {fileName1: {wordFreqMap}, ...}
		
		ArrayList<File> files = FileFinder.GetAllFiles(directory, "", true);
		System.out.println("Found " + files.size() + " files.");
		
		int file_count = 0;
		
		for (File file : files) 
		{
			
			String       file_content  = DocUtils.ReadFile(file);
			List<String> tokensList    = DocUtils.getTokensList(file_content, ignore_stop_words);
			Set<String>  tokensSet     = DocUtils.getTokensSet(tokensList);
			
			// Getting the frequency of each token in the tokensList and creating a dictionary of word and frequency
			Map<String, Integer> wordFreqMap = tokensList.parallelStream().flatMap(s -> Arrays.asList(s.split(" ")).stream()).
		            collect(Collectors.toConcurrentMap(w -> w.toLowerCase(), w -> 1, Integer::sum));
			
			// Adding the file and wordFreqMap to bigFileDictionary
			bigFileDictionary.put(file.getName(), wordFreqMap);
		}
		
		return bigFileDictionary;
	}
	

	public static void main(String[] args) 
	{
		String directory  = "data/blog_data/";
		Map<String, Map> bigFileDictionary = filesToHashMap(directory, true);
		System.out.println(bigFileDictionary);

	}

}
