package KMeans;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import nlp.nicta.filters.StopWordChecker;

public class DocUtils 
{
	public static final String SPLIT_TOKENS = "[!\"#$%&'()*+,./:;<=>?\\[\\]^`{|}~\\s]"; // missing: [_-@]
	
	public static Set<String> getTokensSet(String file_content, boolean ignore_stop_words)
	{
		Set<String>     tokenSet;
		List<String>    tokensList = new ArrayList<String>(); 
		StopWordChecker _swc       = new StopWordChecker();
		
		String[]        tokens     = file_content.split(SPLIT_TOKENS);
		
		for (String token : tokensList) 
		{
			token = token.trim().toLowerCase().replaceAll("ï¿½", "'"); 
			if (token.length() == 0 || (ignore_stop_words  &&  _swc.isStopWord(token)))
				continue;
			tokensList.add(token);
		}
		
		tokenSet = new HashSet<String>(tokensList);
		return tokensSet
		
	}
	
	public static Set<String> getTokensSet(List<String> )

}
